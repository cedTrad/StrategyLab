{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1832316732.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    import tensorflow as import tensorflow as tf\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation='relu')\n",
    "        self.d2 = Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='test_accuracy')\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "\n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(test_images, test_labels)\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch+1,\n",
    "                          train_loss.result(),\n",
    "                          train_accuracy.result()*100,\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, state_size, is_eval = False, model_name = \"\"):\n",
    "        self.state_size = state_size    # normalized previous days\n",
    "        self.action_size = 3\n",
    "        self.memory = deque(max_len = 1000)\n",
    "        self.inventory = []\n",
    "        self.model_name = model_name\n",
    "        self.is_eval = is_eval\n",
    "        \n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        \n",
    "        self.model = load_model(\"models/\"+model_name) if is_eval else self._model()\n",
    "        \n",
    "    \n",
    "    def model(self):\n",
    "        model = Sequential()\n",
    "        modele.add(Dense(units=64, input_dim=self.state_size, activation=\"relu\"))\n",
    "        model.add(Dense(units=32, activation=\"relu\"))\n",
    "        model.add(Dense(units=8, activation=\"relu\"))\n",
    "        model.add(Dense(self.action_size, activation=\"linear\"))\n",
    "        model.compile(loss=\"mse\", optimizer=Adam(lr=0.001))\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def act(self, state):\n",
    "        if not self.is_eval and random.random() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        options = self.model_predict(state)\n",
    "        return np.argmax(options[0])\n",
    "    \n",
    "    def expReplay(self, batch_size):\n",
    "        mini_batch = []\n",
    "        l = len(self.memory)\n",
    "        \n",
    "        # 1 : Prepare replay memory\n",
    "        for i in range(1-batch_size+1, l):\n",
    "            mini_batch.append(self.memory[i])\n",
    "        \n",
    "        # 2 : Loop accross the replay memory batch\n",
    "        for state, action, reward, next_state, done in mini_batch:\n",
    "            target = reward # reward or Q at time t\n",
    "            \n",
    "            # 3 : Update the target for Q table, table equation\n",
    "            if not done:\n",
    "                target = reward + self.gamma\n",
    "                np.amax(self.model.predict(next_state)[0])\n",
    "            \n",
    "            # set_trace()\n",
    "            \n",
    "            # 4 : Update the output Q table for the given action in the table\n",
    "            target_f[0][action] = target\n",
    "            \n",
    "            # 5: Update the output Q table for the given action in the table\n",
    "            target_f[0][action] = target\n",
    "            \n",
    "            # 6: train adn fit the model\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        \n",
    "        # 7 : Implement epsilon greedy algorithm\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrytoEnvironment:\n",
    "    \n",
    "    def __init__(self, assets, capital):\n",
    "        self.assets = assets\n",
    "        self.capital = capital\n",
    "        self.data = self.load_data()\n",
    "        \n",
    "    def load_data(self):\n",
    "        Get_m_data()        \n",
    "    \n",
    "    def preprocess_state(self, state):\n",
    "        return state\n",
    "    \n",
    "    def get_state(self, t, lookback, is_cov_matrix=True, is_raw_time_series=False):\n",
    "        assert lookback <= t\n",
    "        \n",
    "        decision_making_state = self.data.iloc[t - lookback:t]\n",
    "        decision_making_state = decision_making_state.pct_change().dropna()\n",
    "        \n",
    "        if is_cov_matrix:\n",
    "            x = decision_making_state.cov()\n",
    "            return x\n",
    "        else:\n",
    "            if is_raw_time_series:\n",
    "                decision_making_state = self.data.iloc[t-lookback : t]\n",
    "            return self.preprocess_state(decision_making_state)\n",
    "    \n",
    "    def get_reward(self, action, action_t, reward_t, alpha=0.01):\n",
    "        \n",
    "        def local_portfolio(returns, weights):\n",
    "            weights = np.array(weights)\n",
    "            rets = returns.mean()   # * 252\n",
    "            covs = returns.cov()    # * 252\n",
    "            P_ret = np.sum(rets * weights)\n",
    "            P_vol = np.sqrt(np.dot(weights.T, np.dot(covs, weights)))\n",
    "            P_sharpe = P_ret / P_vol\n",
    "            return np.array([P_ret, P_vol, P_sharpe])\n",
    "        \n",
    "        data_period = self.data[action_t : reward_t]\n",
    "        weights = action \n",
    "        returns = data_period.pct_change().dropna()\n",
    "        \n",
    "        sharpe = local_portfolio(returns, weights)[-1]\n",
    "        sharpe = np.array([sharpe] * len(self.data.columns))\n",
    "        ret = (data_period.values[-1] - data_period.valuesp[0]) / data_period.values[0]\n",
    "        \n",
    "        return np.dot(returns, weights), ret\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
